{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a01e39-4cd8-4752-a544-9632af5b2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate();\n",
    "test_file = \"file:///home/jovyan/work/sample/temperature.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97c97e9-d308-4d59-8049-bea4ce2642fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5af7ac6-9716-4f4d-b062-c70ebac2826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_col(line, heaer):\n",
    "    if line != header :\n",
    "        col = line.split(',')\n",
    "        city = col[6].strip(\"\\\"\")\n",
    "        tmp = col[4]\n",
    "        yield(city,tmp)\n",
    "\n",
    "header = lines.first()\n",
    "\n",
    "\n",
    "parse_line = lines.flatMap(lambda line : parse_col(line, header))\n",
    "filtered_line = parse_line.filter(lambda x : 'NA' not in x[1]).mapValues(lambda x : float(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d69494b-a654-4bd4-afd1-c7e8de09b597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Auckland', 49.856),\n",
       " ('Canoas', 50.009),\n",
       " ('Cape Town', 49.9946),\n",
       " ('Hamilton', 44.564),\n",
       " ('Kherson', 7.0952),\n",
       " ('Kiev', 2.85619999999999),\n",
       " ('Lvov', 7.1726),\n",
       " ('Marseille', 39.3908),\n",
       " ('Odesa', 14.8838),\n",
       " ('Stockholm', 13.3988),\n",
       " ('Wroclaw', 9.167),\n",
       " ('NA', 12.4682),\n",
       " ('BrasÃ­lia', 62.9744),\n",
       " ('Johannesburg', 42.1772),\n",
       " ('Paris', 25.0232),\n",
       " ('Tokyo', 29.156),\n",
       " ('Tottori', 34.2518),\n",
       " ('Uppsala', 6.0494),\n",
       " ('Warsaw', 6.8)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_line.reduceByKey(min).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2382325-ae87-4930-ac6c-684752d1a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "test_file = \"file:///home/jovyan/work/sample/house_price.csv\"\n",
    "lines = sc.textFile(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b89189b5-a2c4-4d32-ad43-5729d13d799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_col(line):\n",
    "    col = line.split(\",\")\n",
    "    price = col[1]\n",
    "    cnt = col[2]\n",
    "    return (price,cnt)\n",
    "\n",
    "parse_line = lines.map(lambda line : parse_col(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7295f6fa-f5b8-4d2a-aed9-b048cab1933e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10000', (8, 2)),\n",
       " ('5000', (14, 2)),\n",
       " ('4000', (4, 2)),\n",
       " ('9000', ('4', 1)),\n",
       " ('8000', ('9', 1)),\n",
       " ('40000', ('7', 1))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_line.mapValues(lambda x : (x,1)).reduceByKey(lambda x, y : ((int(x[0])+int(y[0])), (int(x[1])+int(y[1])))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1176e-ad75-44ee-91de-e9ab420d76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d9e44ed-d82a-4ae2-b58c-9709c8434c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SparkSession\n",
    "from pyspark.sql.functions import col, asc, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02a62762-7c8f-4df8-a035-557c1822e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('SparkSQL').getOrCreate()\n",
    "lines = spark.sparkContext.textFile(\"file:///home/jovyan/work/sample/income.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea2bb026-8b9e-479c-80d9-f810063aae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line: str):\n",
    "    col = line.split('|')\n",
    "    return Row (name = str(col[0]),\n",
    "                country = str(col[1]),\n",
    "                email = str(col[2]),\n",
    "                compensation = int(col[3])\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b31958cb-a4ef-4249-ba16-9e09cb9dbd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = lines.map(parse_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b3bdb75-3d35-4f3b-9837-a0381a70505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_income = spark.createDataFrame(data=income_data).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f717fad0-153c-42ad-8134-086c2526970a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+------------+\n",
      "|             name|             country|               email|compensation|\n",
      "+-----------------+--------------------+--------------------+------------+\n",
      "|         Kam Long|            Dominica|VinThomas@example...|      137611|\n",
      "|     Jamey Warner|            Botswana|badlittleduck@tes...|      134999|\n",
      "|      Theola Page|              Malawi|   sharvin@test.mint|      171808|\n",
      "|      Wes Simpson|        Turkmenistan|joshuasortino@exa...|       65429|\n",
      "|  Loriann Hammond|           Argentina|osvaldas@example....|      183451|\n",
      "|     Dannie Watts|Virgin Islands, B...|abdullindenis@tes...|      194254|\n",
      "|    Darby Sanders|         Timor-Leste|suprb@example.xn-...|      195497|\n",
      "| Willian Cummings|             Senegal|    areus@test.canon|       77369|\n",
      "| Patricia Lindsey|              Bhutan|mikemai2awesome@t...|      141602|\n",
      "|       Fae Howell|         Timor-Leste|wr@example.xn--3o...|      147314|\n",
      "|  Annalee Pearson|          Martinique|benefritz@test.fu...|      175067|\n",
      "|     Clarita Gill|             Ecuador| tomaslau@test.games|       86986|\n",
      "|        Wes Kelly|         Puerto Rico|rickdt@example.fi...|      194969|\n",
      "|    Dwain Robbins|             Uruguay|oaktreemedia@test.aw|      146444|\n",
      "|Walter Washington|          Kazakhstan|mbilderbach@examp...|       91072|\n",
      "|    Twanna Garner|         Puerto Rico|       ariil@test.pm|      115333|\n",
      "|       Elroy Dean|            Honduras|aaroni@example.zippo|      198172|\n",
      "|       Lacy Ortiz|Saint Pierre and ...|kushsolitary@exam...|      102871|\n",
      "|   Edgardo Larson|           Venezuela|rohixx@example.vo...|      138680|\n",
      "|   Catarina Hines|               Macao|markjenkins@examp...|       64945|\n",
      "+-----------------+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_income.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06e53db5-947c-4ea1-9d7c-1f31bae41f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_income.createOrReplaceTempView('income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd046413-a117-498c-86b4-aaf8cda2ed97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+--------------------+------------+\n",
      "|             name|             country|               email|compensation|\n",
      "+-----------------+--------------------+--------------------+------------+\n",
      "|         Kam Long|            Dominica|VinThomas@example...|      137611|\n",
      "|     Jamey Warner|            Botswana|badlittleduck@tes...|      134999|\n",
      "|      Theola Page|              Malawi|   sharvin@test.mint|      171808|\n",
      "|      Wes Simpson|        Turkmenistan|joshuasortino@exa...|       65429|\n",
      "|  Loriann Hammond|           Argentina|osvaldas@example....|      183451|\n",
      "|     Dannie Watts|Virgin Islands, B...|abdullindenis@tes...|      194254|\n",
      "|    Darby Sanders|         Timor-Leste|suprb@example.xn-...|      195497|\n",
      "| Willian Cummings|             Senegal|    areus@test.canon|       77369|\n",
      "| Patricia Lindsey|              Bhutan|mikemai2awesome@t...|      141602|\n",
      "|       Fae Howell|         Timor-Leste|wr@example.xn--3o...|      147314|\n",
      "|  Annalee Pearson|          Martinique|benefritz@test.fu...|      175067|\n",
      "|     Clarita Gill|             Ecuador| tomaslau@test.games|       86986|\n",
      "|        Wes Kelly|         Puerto Rico|rickdt@example.fi...|      194969|\n",
      "|    Dwain Robbins|             Uruguay|oaktreemedia@test.aw|      146444|\n",
      "|Walter Washington|          Kazakhstan|mbilderbach@examp...|       91072|\n",
      "|    Twanna Garner|         Puerto Rico|       ariil@test.pm|      115333|\n",
      "|       Elroy Dean|            Honduras|aaroni@example.zippo|      198172|\n",
      "|       Lacy Ortiz|Saint Pierre and ...|kushsolitary@exam...|      102871|\n",
      "|   Edgardo Larson|           Venezuela|rohixx@example.vo...|      138680|\n",
      "|   Catarina Hines|               Macao|markjenkins@examp...|       64945|\n",
      "+-----------------+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"select * from income\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb9ea75c-9e33-44ba-b0cd-6d637d43acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, round as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "61c18596-ccfc-46e3-9998-c3c33ec269a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('sql_import_csv').getOrCreate()\n",
    "path = \"file:///home/jovyan/work/sample/age.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e35448e-f744-4f74-a5a2-f847ce18f09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(path)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a1e3ac4-66bc-46ac-ac81-d41ebc89ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.option(\"header\",\"true\").csv(path)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fbf4f5e5-b745-4cc5-8ea7-24ab48bb6b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.prrintSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0648ea6a-c5ce-478e-ab5f-9d68c788b275",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (894830806.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[82], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    round as rnd\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    col,\n",
    "    round as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f1ffcb6-d6ad-41e4-a771-2fe1d83ba1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+--------------------+\n",
      "|             name|age|             country|\n",
      "+-----------------+---+--------------------+\n",
      "|    Neville Hardy| 56|                Niue|\n",
      "|      Dacia Cohen| 74|Falkland Islands ...|\n",
      "|    Kathey Daniel| 10|            Slovenia|\n",
      "|     Mallie Welch| 12|   Equatorial Guinea|\n",
      "|     Katia Bryant| 14|               Ghana|\n",
      "|Laurice Robertson| 53|        Saudi Arabia|\n",
      "|     Minh Barrett| 27|French Southern T...|\n",
      "|   Latashia Perez| 52|             Finland|\n",
      "|      Elvina Ross| 68|         New Zealand|\n",
      "|  Augustus Snyder| 20|             Jamaica|\n",
      "|        Elois Cox| 65|            Paraguay|\n",
      "|    Jolanda Dixon| 14|               Ghana|\n",
      "|      Rutha Young| 10|        Saint Helena|\n",
      "| Waltraud Holland| 10|             Moldova|\n",
      "|   Colton Flowers| 77|Saint Vincent and...|\n",
      "|     Meri Hawkins| 43|             Jamaica|\n",
      "|     Theola Mason| 71|              Gambia|\n",
      "|  Antonia Pearson| 25|             Namibia|\n",
      "|   Delicia Murray| 41|         El Salvador|\n",
      "|    Cicely Harvey| 37|              Belize|\n",
      "+-----------------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb7cd8d1-93e1-4783-8a6e-c9a938154e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|             name|age|\n",
      "+-----------------+---+\n",
      "|    Neville Hardy| 56|\n",
      "|      Dacia Cohen| 74|\n",
      "|    Kathey Daniel| 10|\n",
      "|     Mallie Welch| 12|\n",
      "|     Katia Bryant| 14|\n",
      "|Laurice Robertson| 53|\n",
      "|     Minh Barrett| 27|\n",
      "|   Latashia Perez| 52|\n",
      "|      Elvina Ross| 68|\n",
      "|  Augustus Snyder| 20|\n",
      "|        Elois Cox| 65|\n",
      "|    Jolanda Dixon| 14|\n",
      "|      Rutha Young| 10|\n",
      "| Waltraud Holland| 10|\n",
      "|   Colton Flowers| 77|\n",
      "|     Meri Hawkins| 43|\n",
      "|     Theola Mason| 71|\n",
      "|  Antonia Pearson| 25|\n",
      "|   Delicia Murray| 41|\n",
      "|    Cicely Harvey| 37|\n",
      "+-----------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('name','age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fbdcea7-f92b-4ed5-b98a-e0950df09410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+--------------------+\n",
      "|             name|age|             country|\n",
      "+-----------------+---+--------------------+\n",
      "|    Neville Hardy| 56|                Niue|\n",
      "|      Dacia Cohen| 74|Falkland Islands ...|\n",
      "|Laurice Robertson| 53|        Saudi Arabia|\n",
      "|     Minh Barrett| 27|French Southern T...|\n",
      "|   Latashia Perez| 52|             Finland|\n",
      "|      Elvina Ross| 68|         New Zealand|\n",
      "|        Elois Cox| 65|            Paraguay|\n",
      "|   Colton Flowers| 77|Saint Vincent and...|\n",
      "|     Meri Hawkins| 43|             Jamaica|\n",
      "|     Theola Mason| 71|              Gambia|\n",
      "|  Antonia Pearson| 25|             Namibia|\n",
      "|   Delicia Murray| 41|         El Salvador|\n",
      "|    Cicely Harvey| 37|              Belize|\n",
      "|    Berry Russell| 49|       New Caledonia|\n",
      "|   Lauryn Hubbard| 80|           Mauritius|\n",
      "|    Judson Willis| 34|              Sweden|\n",
      "|     Junita Meyer| 49|             Moldova|\n",
      "|        Apryl Fox| 48|            Maldives|\n",
      "|   Dorsey Wheeler| 56|Sao Tome and Prin...|\n",
      "|       Jae Duncan| 47|              Norway|\n",
      "+-----------------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data.age > 20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5934f029-be02-465d-bb74-d443076d9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"sql_import_csv\").getOrCreate()\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/age.csv\"\n",
    "\n",
    "# header option: either csv has header or not(default: header = false)\n",
    "# inferSchema: either all columns are str or not\n",
    "data = spark.read.option(\"header\", \"true\")\\\n",
    "                 .option(\"inferSchema\", \"true\")\\\n",
    "                 .csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3d184ee7-1b09-4d6e-9ae2-6ebe0bbb55b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             country|          avg(age)|\n",
      "+--------------------+------------------+\n",
      "|                Chad|             36.25|\n",
      "|            Paraguay| 47.77777777777778|\n",
      "|            Anguilla|              72.0|\n",
      "|               Macao|              72.0|\n",
      "|Heard Island and ...|              30.0|\n",
      "|             Senegal|              53.0|\n",
      "|              Sweden|45.333333333333336|\n",
      "|             Tokelau|34.166666666666664|\n",
      "|French Southern T...|50.666666666666664|\n",
      "|            Kiribati|48.666666666666664|\n",
      "|   Republic of Korea|58.166666666666664|\n",
      "|              Guyana|              39.0|\n",
      "|             Eritrea|             39.75|\n",
      "|              Jersey|              58.8|\n",
      "|         Philippines|48.333333333333336|\n",
      "|            Djibouti|              38.6|\n",
      "|               Tonga|              49.0|\n",
      "|      Norfolk Island|35.333333333333336|\n",
      "|            Malaysia|60.666666666666664|\n",
      "|           Singapore|              40.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(data.country, data.age).groupBy(\"country\").avg(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ab76f218-c0e6-41b1-9d0a-c959c7ed0eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|             name|age|\n",
      "+-----------------+---+\n",
      "|    Neville Hardy| 56|\n",
      "|      Dacia Cohen| 74|\n",
      "|    Kathey Daniel| 10|\n",
      "|     Mallie Welch| 12|\n",
      "|     Katia Bryant| 14|\n",
      "|Laurice Robertson| 53|\n",
      "|     Minh Barrett| 27|\n",
      "|   Latashia Perez| 52|\n",
      "|      Elvina Ross| 68|\n",
      "|  Augustus Snyder| 20|\n",
      "|        Elois Cox| 65|\n",
      "|    Jolanda Dixon| 14|\n",
      "|      Rutha Young| 10|\n",
      "| Waltraud Holland| 10|\n",
      "|   Colton Flowers| 77|\n",
      "|     Meri Hawkins| 43|\n",
      "|     Theola Mason| 71|\n",
      "|  Antonia Pearson| 25|\n",
      "|   Delicia Murray| 41|\n",
      "|    Cicely Harvey| 37|\n",
      "+-----------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('name','age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "93ffd15b-2906-4cdb-976f-b565e36409fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|             name|age|\n",
      "+-----------------+---+\n",
      "|    Neville Hardy| 56|\n",
      "|      Dacia Cohen| 74|\n",
      "|    Kathey Daniel| 10|\n",
      "|     Mallie Welch| 12|\n",
      "|     Katia Bryant| 14|\n",
      "|Laurice Robertson| 53|\n",
      "|     Minh Barrett| 27|\n",
      "|   Latashia Perez| 52|\n",
      "|      Elvina Ross| 68|\n",
      "|  Augustus Snyder| 20|\n",
      "|        Elois Cox| 65|\n",
      "|    Jolanda Dixon| 14|\n",
      "|      Rutha Young| 10|\n",
      "| Waltraud Holland| 10|\n",
      "|   Colton Flowers| 77|\n",
      "|     Meri Hawkins| 43|\n",
      "|     Theola Mason| 71|\n",
      "|  Antonia Pearson| 25|\n",
      "|   Delicia Murray| 41|\n",
      "|    Cicely Harvey| 37|\n",
      "+-----------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(data.name,data.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bb23cb09-3799-4e48-a637-31d026fca9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+\n",
      "|           name|age|\n",
      "+---------------+---+\n",
      "|    Dacia Cohen| 74|\n",
      "| Colton Flowers| 77|\n",
      "|   Theola Mason| 71|\n",
      "| Lauryn Hubbard| 80|\n",
      "|  Verena Dennis| 80|\n",
      "|    Gaston Ford| 76|\n",
      "|    Lory Austin| 76|\n",
      "|      Otha Soto| 72|\n",
      "|  Kristofer Roy| 74|\n",
      "|  Janee Holland| 80|\n",
      "|  Mitchell Rios| 73|\n",
      "|Doloris Pearson| 72|\n",
      "|     Enoch Beck| 75|\n",
      "|       Tai Pope| 73|\n",
      "|     Chery Dean| 79|\n",
      "|   Donn Mullins| 77|\n",
      "|  Kasie Simmons| 74|\n",
      "|   Dyan Mendoza| 76|\n",
      "|Daron Mccormick| 72|\n",
      "|Rashad Holloway| 79|\n",
      "+---------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(data.name, data.age).filter(data.age > 70).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a3511554-a394-4330-b981-e8ed4be63382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 31|   16|\n",
      "| 65|   16|\n",
      "| 53|   14|\n",
      "| 78|   16|\n",
      "| 34|   15|\n",
      "| 28|   11|\n",
      "| 76|   14|\n",
      "| 27|   10|\n",
      "| 26|   15|\n",
      "| 44|   14|\n",
      "| 12|   15|\n",
      "| 22|   17|\n",
      "| 47|   17|\n",
      "| 52|   16|\n",
      "| 13|   14|\n",
      "| 16|   18|\n",
      "| 20|   12|\n",
      "| 40|   22|\n",
      "| 57|    9|\n",
      "| 54|   17|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d68322f9-9fff-47b6-b5c8-4138c7c64771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+-------+\n",
      "|             name|age|new_age|\n",
      "+-----------------+---+-------+\n",
      "|    Neville Hardy| 56|     46|\n",
      "|      Dacia Cohen| 74|     64|\n",
      "|    Kathey Daniel| 10|      0|\n",
      "|     Mallie Welch| 12|      2|\n",
      "|     Katia Bryant| 14|      4|\n",
      "|Laurice Robertson| 53|     43|\n",
      "|     Minh Barrett| 27|     17|\n",
      "|   Latashia Perez| 52|     42|\n",
      "|      Elvina Ross| 68|     58|\n",
      "|  Augustus Snyder| 20|     10|\n",
      "|        Elois Cox| 65|     55|\n",
      "|    Jolanda Dixon| 14|      4|\n",
      "|      Rutha Young| 10|      0|\n",
      "| Waltraud Holland| 10|      0|\n",
      "|   Colton Flowers| 77|     67|\n",
      "|     Meri Hawkins| 43|     33|\n",
      "|     Theola Mason| 71|     61|\n",
      "|  Antonia Pearson| 25|     15|\n",
      "|   Delicia Murray| 41|     31|\n",
      "|    Cicely Harvey| 37|     27|\n",
      "+-----------------+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(data.name, data.age, (data.age - 10).alias('new_age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a122e035-6582-4c99-a6f4-e06e9890fc18",
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_ITERABLE] Column is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountry\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcountry\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/group.py:49\u001b[0m, in \u001b[0;36mdf_varargs_api.<locals>._api\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_api\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroupedData\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m     48\u001b[0m     name \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 49\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jgd, name)(\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/column.py:90\u001b[0m, in \u001b[0;36m_to_seq\u001b[0;34m(sc, cols, converter)\u001b[0m\n\u001b[1;32m     88\u001b[0m     cols \u001b[38;5;241m=\u001b[39m [converter(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols]\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1314\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1314\u001b[0m     args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m     command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m         args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m         proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1277\u001b[0m, in \u001b[0;36mJavaMember._build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1277\u001b[0m         (new_args, temp_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1279\u001b[0m         new_args \u001b[38;5;241m=\u001b[39m args\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1264\u001b[0m, in \u001b[0;36mJavaMember._get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m converter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39mconverters:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter\u001b[38;5;241m.\u001b[39mcan_convert(arg):\n\u001b[0;32m-> 1264\u001b[0m         temp_arg \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m         temp_args\u001b[38;5;241m.\u001b[39mappend(temp_arg)\n\u001b[1;32m   1266\u001b[0m         new_args\u001b[38;5;241m.\u001b[39mappend(temp_arg)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_collections.py:511\u001b[0m, in \u001b[0;36mListConverter.convert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    509\u001b[0m java_list \u001b[38;5;241m=\u001b[39m ArrayList()\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 511\u001b[0m     \u001b[43mjava_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m java_list\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1314\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1314\u001b[0m     args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m     command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m         args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m         proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1277\u001b[0m, in \u001b[0;36mJavaMember._build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1277\u001b[0m         (new_args, temp_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1279\u001b[0m         new_args \u001b[38;5;241m=\u001b[39m args\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1264\u001b[0m, in \u001b[0;36mJavaMember._get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m converter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39mconverters:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter\u001b[38;5;241m.\u001b[39mcan_convert(arg):\n\u001b[0;32m-> 1264\u001b[0m         temp_arg \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m         temp_args\u001b[38;5;241m.\u001b[39mappend(temp_arg)\n\u001b[1;32m   1266\u001b[0m         new_args\u001b[38;5;241m.\u001b[39mappend(temp_arg)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_collections.py:510\u001b[0m, in \u001b[0;36mListConverter.convert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    508\u001b[0m ArrayList \u001b[38;5;241m=\u001b[39m JavaClass(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava.util.ArrayList\u001b[39m\u001b[38;5;124m\"\u001b[39m, gateway_client)\n\u001b[1;32m    509\u001b[0m java_list \u001b[38;5;241m=\u001b[39m ArrayList()\n\u001b[0;32m--> 510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    511\u001b[0m     java_list\u001b[38;5;241m.\u001b[39madd(element)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m java_list\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/column.py:718\u001b[0m, in \u001b[0;36mColumn.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    719\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_ITERABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m, message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjectName\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    720\u001b[0m     )\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_ITERABLE] Column is not iterable."
     ]
    }
   ],
   "source": [
    "data.select(data.name, data.age, data.country).groupBy(data.country).avg(data.age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ed82a-d89f-477a-a89b-66be82708acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select(data.name, data.age, data.country).groupBy(\"country\").avg(\"age\").sort(\"avg(age)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7fdff-4e5e-47f6-8499-d548dcd025e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "25aac6fc-3de4-437b-ad0a-b4a9694301b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import (functions,Row, SparkSession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea2acc37-1b3e-48c6-a3ba-61669cd7e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"df_wordcount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32479430-727c-457d-b420-401ba425ad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------+\n",
      "|  a|  intlist|mapfield|\n",
      "+---+---------+--------+\n",
      "|  1|[1, 2, 3]|{a -> b}|\n",
      "+---+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "        Row(a=1,\n",
    "            intlist=[1,2,3],\n",
    "            mapfield={\"a\": \"b\"}\n",
    "           )])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b51faed9-b7c4-4c2c-ba2e-5cb35b41ee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|anInt|\n",
      "+-----+\n",
      "|    1|\n",
      "|    2|\n",
      "|    3|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(functions.explode(df.intlist).alias(\"anInt\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cfd12ea4-6d2d-4206-aa05-609c624fe612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                word|\n",
      "+--------------------+\n",
      "|hello world and p...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([Row(word=\"hello world and pyspark\")])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e9db005f-7e5b-44d6-a0f3-99aa501254c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   word|\n",
      "+-------+\n",
      "|  hello|\n",
      "|  world|\n",
      "|    and|\n",
      "|pyspark|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(functions.explode(\n",
    "            functions.split(df.word, ' ')).alias(\"word\")\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3d11981a-b325-4b4b-9aa0-b0c71d1907ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Lorem ipsum dolor...|\n",
      "|Metus aliquam ele...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = \"file:///home/jovyan/work/sample/lorem_ipsum.txt\"\n",
    "df = spark.read.text(csv_file_path)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fe4528df-c371-4259-8f81-10d51eef040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Lorem ipsum dolor...|\n",
      "|Metus aliquam ele...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "69501bed-1216-457b-8343-f93717772717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                word|\n",
      "+--------------------+\n",
      "|[Lorem, ipsum, do...|\n",
      "|[Metus, aliquam, ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = df.select(functions.split(df.value, ' ').alias('word'))\n",
    "word.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7237d6de-363a-4126-9506-713dbdc93d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|      Lorem|\n",
      "|      ipsum|\n",
      "|      dolor|\n",
      "|        sit|\n",
      "|      amet,|\n",
      "|consectetur|\n",
      "| adipiscing|\n",
      "|      elit,|\n",
      "|        sed|\n",
      "|         do|\n",
      "|    eiusmod|\n",
      "|     tempor|\n",
      "| incididunt|\n",
      "|         ut|\n",
      "|     labore|\n",
      "|         et|\n",
      "|     dolore|\n",
      "|      magna|\n",
      "|    aliqua.|\n",
      "|         Et|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = df.select(functions.explode(functions.split(df.value, ' ')).alias(\"word\"))\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f9cce889-7ca2-42db-8dbf-36cc29409f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|         sit|    6|\n",
      "|        amet|    5|\n",
      "|          in|    4|\n",
      "|sollicitudin|    3|\n",
      "|     gravida|    3|\n",
      "|          et|    3|\n",
      "|      tellus|    3|\n",
      "|          id|    3|\n",
      "|    interdum|    2|\n",
      "|        quam|    2|\n",
      "|   fermentum|    2|\n",
      "|     laoreet|    2|\n",
      "|   malesuada|    2|\n",
      "|        diam|    2|\n",
      "|     commodo|    2|\n",
      "|     cursus.|    2|\n",
      "|       magna|    2|\n",
      "|        eget|    2|\n",
      "|       nulla|    2|\n",
      "|         sed|    2|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words.groupBy(words.word).count().orderBy(functions.col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2ddb71b7-f2e4-4b1b-8371-c15300bca7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions, SparkSession, Row\n",
    "\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/lorem_ipsum.txt\"\n",
    "df = spark.read.text(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e6815d92-c944-49e0-885a-7f4b0875439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|Lorem ipsum dolor...|\n",
      "|Metus aliquam ele...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c1813c00-d72a-454d-8710-3bf9f6cf3c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| split(value,  , -1)|\n",
      "+--------------------+\n",
      "|[Lorem, ipsum, do...|\n",
      "|[Metus, aliquam, ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(functions.split(df.value,' ')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc4a25b6-cbff-4a13-b2d6-8171063f90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = df.select(functions.explode(functions.split(df.value, ' ')).alias('val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "99c73cc6-acf0-479c-91d3-1416acf4b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|        val|\n",
      "+-----------+\n",
      "|      Lorem|\n",
      "|      ipsum|\n",
      "|      dolor|\n",
      "|        sit|\n",
      "|      amet,|\n",
      "|consectetur|\n",
      "| adipiscing|\n",
      "|      elit,|\n",
      "|        sed|\n",
      "|         do|\n",
      "|    eiusmod|\n",
      "|     tempor|\n",
      "| incididunt|\n",
      "|         ut|\n",
      "|     labore|\n",
      "|         et|\n",
      "|     dolore|\n",
      "|      magna|\n",
      "|    aliqua.|\n",
      "|         Et|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7d886d4b-f427-4d3c-bd66-b5271e227c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|         val|count|\n",
      "+------------+-----+\n",
      "|         sit|    6|\n",
      "|        amet|    5|\n",
      "|          in|    4|\n",
      "|sollicitudin|    3|\n",
      "|     gravida|    3|\n",
      "|          et|    3|\n",
      "|      tellus|    3|\n",
      "|          id|    3|\n",
      "|    interdum|    2|\n",
      "|        quam|    2|\n",
      "|   fermentum|    2|\n",
      "|     laoreet|    2|\n",
      "|   malesuada|    2|\n",
      "|        diam|    2|\n",
      "|     commodo|    2|\n",
      "|     cursus.|    2|\n",
      "|       magna|    2|\n",
      "|        eget|    2|\n",
      "|       nulla|    2|\n",
      "|         sed|    2|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat.groupBy('val').count().orderBy(functions.col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dec6b0e8-0c5f-4d42-aa2a-a0ebaab94966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f, Row, types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2edf6bc0-1764-43a2-86ad-22eb58ff4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"df_struct\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f4455f4d-f912-41df-b525-0a4670308350",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"file:///home/jovyan/work/sample/temp_with_date.csv\"\n",
    "df = spark.read.csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fc8905fd-818b-488b-b841-80950b2b8fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----------+\n",
      "|                 _c0|_c1|       _c2|\n",
      "+--------------------+---+----------+\n",
      "|                Guam|-25|2022-03-25|\n",
      "|                Guam| 39|2022-02-18|\n",
      "|              Serbia|-35|2022-08-31|\n",
      "|       French Guiana| -6|2022-04-03|\n",
      "|Falkland Islands ...|-40|2022-05-26|\n",
      "|              Brazil| 15|2022-02-11|\n",
      "|             Tunisia|-31|2022-09-20|\n",
      "|            Portugal|  7|2022-01-02|\n",
      "|                Iran|-22|2022-08-14|\n",
      "|           Australia| -5|2022-01-12|\n",
      "|              Gambia| 21|2022-08-08|\n",
      "|               Italy| 31|2022-08-26|\n",
      "|          Guadeloupe|-39|2022-07-13|\n",
      "|        South Africa|-24|2022-05-02|\n",
      "|              Malawi| -6|2022-06-13|\n",
      "|                Iran| 34|2022-09-28|\n",
      "|      Norfolk Island| -5|2022-02-21|\n",
      "|Lao People's Demo...| 25|2022-11-17|\n",
      "|   Republic of Korea|-18|2022-07-13|\n",
      "|           Singapore|-15|2022-05-18|\n",
      "+--------------------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "abc0b963-77f9-4f38-95b8-da3a7c48ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_schema = t.StructType([\n",
    "    t.StructField(\"city\",t.StringType(),True),\n",
    "    t.StructField(\"tmp\",t.FloatType(),True),\n",
    "    t.StructField(\"dat\",t.StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "244166f8-2715-4abf-9216-f6315ff53f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.schema(table_schema).csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6c7df3d4-cda0-4b02-ae06-fbf38aba6552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                city|  tmp|       dat|\n",
      "+--------------------+-----+----------+\n",
      "|                Guam|-25.0|2022-03-25|\n",
      "|                Guam| 39.0|2022-02-18|\n",
      "|              Serbia|-35.0|2022-08-31|\n",
      "|       French Guiana| -6.0|2022-04-03|\n",
      "|Falkland Islands ...|-40.0|2022-05-26|\n",
      "|              Brazil| 15.0|2022-02-11|\n",
      "|             Tunisia|-31.0|2022-09-20|\n",
      "|            Portugal|  7.0|2022-01-02|\n",
      "|                Iran|-22.0|2022-08-14|\n",
      "|           Australia| -5.0|2022-01-12|\n",
      "|              Gambia| 21.0|2022-08-08|\n",
      "|               Italy| 31.0|2022-08-26|\n",
      "|          Guadeloupe|-39.0|2022-07-13|\n",
      "|        South Africa|-24.0|2022-05-02|\n",
      "|              Malawi| -6.0|2022-06-13|\n",
      "|                Iran| 34.0|2022-09-28|\n",
      "|      Norfolk Island| -5.0|2022-02-21|\n",
      "|Lao People's Demo...| 25.0|2022-11-17|\n",
      "|   Republic of Korea|-18.0|2022-07-13|\n",
      "|           Singapore|-15.0|2022-05-18|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "732abc3f-de17-4fe0-858f-9217d8212cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                city|  tmp|       dat|\n",
      "+--------------------+-----+----------+\n",
      "|                Guam|-25.0|2022-03-25|\n",
      "|                Guam| 39.0|2022-02-18|\n",
      "|              Serbia|-35.0|2022-08-31|\n",
      "|       French Guiana| -6.0|2022-04-03|\n",
      "|Falkland Islands ...|-40.0|2022-05-26|\n",
      "|              Brazil| 15.0|2022-02-11|\n",
      "|             Tunisia|-31.0|2022-09-20|\n",
      "|            Portugal|  7.0|2022-01-02|\n",
      "|                Iran|-22.0|2022-08-14|\n",
      "|           Australia| -5.0|2022-01-12|\n",
      "|              Gambia| 21.0|2022-08-08|\n",
      "|               Italy| 31.0|2022-08-26|\n",
      "|          Guadeloupe|-39.0|2022-07-13|\n",
      "|        South Africa|-24.0|2022-05-02|\n",
      "|              Malawi| -6.0|2022-06-13|\n",
      "|                Iran| 34.0|2022-09-28|\n",
      "|      Norfolk Island| -5.0|2022-02-21|\n",
      "|Lao People's Demo...| 25.0|2022-11-17|\n",
      "|   Republic of Korea|-18.0|2022-07-13|\n",
      "|           Singapore|-15.0|2022-05-18|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5e82ed1f-63ac-48f0-80e4-fc9f30a6fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.select(\"city\", \"tmp\", \"dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "abad4979-7225-4f90-b46a-196c40a53648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                city|min(tmp)|\n",
      "+--------------------+--------+\n",
      "|                Chad|   -24.0|\n",
      "|            Anguilla|   -40.0|\n",
      "|            Paraguay|    30.0|\n",
      "|               Macao|   -34.0|\n",
      "|Heard Island and ...|   -39.0|\n",
      "|               Yemen|   -33.0|\n",
      "|             Senegal|   -21.0|\n",
      "|              Sweden|   -29.0|\n",
      "|             Tokelau|   -35.0|\n",
      "|            Kiribati|   -26.0|\n",
      "|French Southern T...|   -22.0|\n",
      "|   Republic of Korea|   -18.0|\n",
      "|              Guyana|   -28.0|\n",
      "|             Eritrea|   -40.0|\n",
      "|         Philippines|   -34.0|\n",
      "|              Jersey|   -21.0|\n",
      "|      Norfolk Island|   -28.0|\n",
      "|               Tonga|   -40.0|\n",
      "|           Singapore|   -25.0|\n",
      "|            Malaysia|   -21.0|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.city).min(\"tmp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c150ee63-e9b2-4f3a-b21a-f2e9777c1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tmp = df.groupBy(df.city).min(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d6fb290f-e076-4da0-83ba-3bf6a567e12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                city|min(tmp)|\n",
      "+--------------------+--------+\n",
      "|                Chad|   -24.0|\n",
      "|            Anguilla|   -40.0|\n",
      "|            Paraguay|    30.0|\n",
      "|               Macao|   -34.0|\n",
      "|Heard Island and ...|   -39.0|\n",
      "|               Yemen|   -33.0|\n",
      "|             Senegal|   -21.0|\n",
      "|              Sweden|   -29.0|\n",
      "|             Tokelau|   -35.0|\n",
      "|            Kiribati|   -26.0|\n",
      "|French Southern T...|   -22.0|\n",
      "|   Republic of Korea|   -18.0|\n",
      "|              Guyana|   -28.0|\n",
      "|             Eritrea|   -40.0|\n",
      "|         Philippines|   -34.0|\n",
      "|              Jersey|   -21.0|\n",
      "|      Norfolk Island|   -28.0|\n",
      "|               Tonga|   -40.0|\n",
      "|           Singapore|   -25.0|\n",
      "|            Malaysia|   -21.0|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9c4e42c7-e8b2-400c-82df-f7c265d7ae8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                city|                tmp|\n",
      "+--------------------+-------------------+\n",
      "|                Guam|              -13.0|\n",
      "|                Guam|              102.2|\n",
      "|              Serbia|              -31.0|\n",
      "|       French Guiana|               21.2|\n",
      "|Falkland Islands ...|              -40.0|\n",
      "|              Brazil|               59.0|\n",
      "|             Tunisia|-23.799999999999997|\n",
      "|            Portugal|               44.6|\n",
      "|                Iran| -7.600000000000001|\n",
      "|           Australia|               23.0|\n",
      "|              Gambia|               69.8|\n",
      "|               Italy|               87.8|\n",
      "|          Guadeloupe|              -38.2|\n",
      "|        South Africa|-11.200000000000003|\n",
      "|              Malawi|               21.2|\n",
      "|                Iran|               93.2|\n",
      "|      Norfolk Island|               23.0|\n",
      "|Lao People's Demo...|               77.0|\n",
      "|   Republic of Korea|-0.3999999999999986|\n",
      "|           Singapore|                5.0|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_temperature = data.withColumn(\"tmp\",(f.col(\"tmp\") * 9 / 5) + 32).select(\"city\", \"tmp\")\n",
    "f_temperature.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5d9802df-94d2-4848-9a3b-cdc9ae3472ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+----------+\n",
      "|                city|  tmp| tmp2|       dat|\n",
      "+--------------------+-----+-----+----------+\n",
      "|                Guam|-25.0|  0.0|2022-03-25|\n",
      "|                Guam| 39.0| 64.0|2022-02-18|\n",
      "|              Serbia|-35.0|-10.0|2022-08-31|\n",
      "|       French Guiana| -6.0| 19.0|2022-04-03|\n",
      "|Falkland Islands ...|-40.0|-15.0|2022-05-26|\n",
      "|              Brazil| 15.0| 40.0|2022-02-11|\n",
      "|             Tunisia|-31.0| -6.0|2022-09-20|\n",
      "|            Portugal|  7.0| 32.0|2022-01-02|\n",
      "|                Iran|-22.0|  3.0|2022-08-14|\n",
      "|           Australia| -5.0| 20.0|2022-01-12|\n",
      "|              Gambia| 21.0| 46.0|2022-08-08|\n",
      "|               Italy| 31.0| 56.0|2022-08-26|\n",
      "|          Guadeloupe|-39.0|-14.0|2022-07-13|\n",
      "|        South Africa|-24.0|  1.0|2022-05-02|\n",
      "|              Malawi| -6.0| 19.0|2022-06-13|\n",
      "|                Iran| 34.0| 59.0|2022-09-28|\n",
      "|      Norfolk Island| -5.0| 20.0|2022-02-21|\n",
      "|Lao People's Demo...| 25.0| 50.0|2022-11-17|\n",
      "|   Republic of Korea|-18.0|  7.0|2022-07-13|\n",
      "|           Singapore|-15.0| 10.0|2022-05-18|\n",
      "+--------------------+-----+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.withColumn(\"tmp2\",(f.col(\"tmp\")+ 25)).select(\"city\",\"tmp\",\"tmp2\",\"dat\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a1199cb2-b45c-4b76-9946-0dcd79d21ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                city|  tmp|       dat|\n",
      "+--------------------+-----+----------+\n",
      "|                Guam|  0.0|2022-03-25|\n",
      "|                Guam| 64.0|2022-02-18|\n",
      "|              Serbia|-10.0|2022-08-31|\n",
      "|       French Guiana| 19.0|2022-04-03|\n",
      "|Falkland Islands ...|-15.0|2022-05-26|\n",
      "|              Brazil| 40.0|2022-02-11|\n",
      "|             Tunisia| -6.0|2022-09-20|\n",
      "|            Portugal| 32.0|2022-01-02|\n",
      "|                Iran|  3.0|2022-08-14|\n",
      "|           Australia| 20.0|2022-01-12|\n",
      "|              Gambia| 46.0|2022-08-08|\n",
      "|               Italy| 56.0|2022-08-26|\n",
      "|          Guadeloupe|-14.0|2022-07-13|\n",
      "|        South Africa|  1.0|2022-05-02|\n",
      "|              Malawi| 19.0|2022-06-13|\n",
      "|                Iran| 59.0|2022-09-28|\n",
      "|      Norfolk Island| 20.0|2022-02-21|\n",
      "|Lao People's Demo...| 50.0|2022-11-17|\n",
      "|   Republic of Korea|  7.0|2022-07-13|\n",
      "|           Singapore| 10.0|2022-05-18|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(data.city,  (data.tmp+25).alias('tmp') ,data.dat).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "085bc41f-80f7-4909-9efe-ada77c7b5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf2 =df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0677bb8d-14f6-4dc5-a7d0-0b02693bda58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----------+\n",
      "|                 _c0|_c1|       _c2|\n",
      "+--------------------+---+----------+\n",
      "|                Guam|-25|2022-03-25|\n",
      "|                Guam| 39|2022-02-18|\n",
      "|              Serbia|-35|2022-08-31|\n",
      "|       French Guiana| -6|2022-04-03|\n",
      "|Falkland Islands ...|-40|2022-05-26|\n",
      "|              Brazil| 15|2022-02-11|\n",
      "|             Tunisia|-31|2022-09-20|\n",
      "|            Portugal|  7|2022-01-02|\n",
      "|                Iran|-22|2022-08-14|\n",
      "|           Australia| -5|2022-01-12|\n",
      "|              Gambia| 21|2022-08-08|\n",
      "|               Italy| 31|2022-08-26|\n",
      "|          Guadeloupe|-39|2022-07-13|\n",
      "|        South Africa|-24|2022-05-02|\n",
      "|              Malawi| -6|2022-06-13|\n",
      "|                Iran| 34|2022-09-28|\n",
      "|      Norfolk Island| -5|2022-02-21|\n",
      "|Lao People's Demo...| 25|2022-11-17|\n",
      "|   Republic of Korea|-18|2022-07-13|\n",
      "|           Singapore|-15|2022-05-18|\n",
      "+--------------------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "aac7780b-e932-4d6d-bc73-11b0c2c607d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----------+\n",
      "|                city|tmp|       dat|\n",
      "+--------------------+---+----------+\n",
      "|                Guam|-25|2022-03-25|\n",
      "|                Guam| 39|2022-02-18|\n",
      "|              Serbia|-35|2022-08-31|\n",
      "|       French Guiana| -6|2022-04-03|\n",
      "|Falkland Islands ...|-40|2022-05-26|\n",
      "|              Brazil| 15|2022-02-11|\n",
      "|             Tunisia|-31|2022-09-20|\n",
      "|            Portugal|  7|2022-01-02|\n",
      "|                Iran|-22|2022-08-14|\n",
      "|           Australia| -5|2022-01-12|\n",
      "|              Gambia| 21|2022-08-08|\n",
      "|               Italy| 31|2022-08-26|\n",
      "|          Guadeloupe|-39|2022-07-13|\n",
      "|        South Africa|-24|2022-05-02|\n",
      "|              Malawi| -6|2022-06-13|\n",
      "|                Iran| 34|2022-09-28|\n",
      "|      Norfolk Island| -5|2022-02-21|\n",
      "|Lao People's Demo...| 25|2022-11-17|\n",
      "|   Republic of Korea|-18|2022-07-13|\n",
      "|           Singapore|-15|2022-05-18|\n",
      "+--------------------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "header = ['city','tmp','dat']\n",
    "df2 = df2.toDF(*header)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ef347670-11a3-49d8-bf8f-50ac7ebe2153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# SparkSession ìì± (íìí ê²½ì°)\n",
    "spark = SparkSession.builder.appName(\"ComplexColumnTransformation\").getOrCreate()\n",
    "\n",
    "# ìì ë°ì´í° (DataFrame ìì±)\n",
    "data = spark.createDataFrame([\n",
    "    (10000, 0.1, \"VIP\", 2, \"credit_card\", \"2023-06-09 10:30:00\"),\n",
    "    (25000, 0.05, \"NORMAL\", 1, \"bank_transfer\", \"2023-06-09 19:45:00\")\n",
    "], [\"price\", \"discount_rate\", \"customer_grade\", \"quantity\", \"payment_method\", \"purchase_time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dbe95626-5dcf-4991-8944-7e951cf11ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------+--------+--------------+-------------------+\n",
      "|price|discount_rate|customer_grade|quantity|payment_method|      purchase_time|\n",
      "+-----+-------------+--------------+--------+--------------+-------------------+\n",
      "|10000|          0.1|           VIP|       2|   credit_card|2023-06-09 10:30:00|\n",
      "|25000|         0.05|        NORMAL|       1| bank_transfer|2023-06-09 19:45:00|\n",
      "+-----+-------------+--------------+--------+--------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d4c68cbe-e03a-44e7-b115-14a39c68806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------+--------+--------------+-------------------+----------------+-------------+------------------+-------------+-----------+\n",
      "|price|discount_rate|customer_grade|quantity|payment_method|      purchase_time|discounted_price|total_payment|payment_method_num|purchase_hour|hour_period|\n",
      "+-----+-------------+--------------+--------+--------------+-------------------+----------------+-------------+------------------+-------------+-----------+\n",
      "|10000|          0.1|           VIP|       2|   credit_card|2023-06-09 10:30:00|          8500.0|      17000.0|                 1|           10|       ì¤ì |\n",
      "|25000|         0.05|        NORMAL|       1| bank_transfer|2023-06-09 19:45:00|         23750.0|      23750.0|                 2|           19|       ì ë|\n",
      "+-----+-------------+--------------+--------+--------------+-------------------+----------------+-------------+------------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# SparkSession ìì± (íìí ê²½ì°)\n",
    "spark = SparkSession.builder.appName(\"ComplexColumnTransformation\").getOrCreate()\n",
    "\n",
    "# ìì ë°ì´í° (DataFrame ìì±)\n",
    "data = spark.createDataFrame([\n",
    "    (10000, 0.1, \"VIP\", 2, \"credit_card\", \"2023-06-09 10:30:00\"),\n",
    "    (25000, 0.05, \"NORMAL\", 1, \"bank_transfer\", \"2023-06-09 19:45:00\")\n",
    "], [\"price\", \"discount_rate\", \"customer_grade\", \"quantity\", \"payment_method\", \"purchase_time\"])\n",
    "\n",
    "# ë³µì¡í ì´ ë³í ìì\n",
    "transformed_data = (data\n",
    "    .withColumn(\"discounted_price\", F.when(F.col(\"customer_grade\") == \"VIP\", F.col(\"price\") * (1 - F.col(\"discount_rate\") - 0.05)).otherwise(F.col(\"price\") * (1 - F.col(\"discount_rate\"))))\n",
    "    .withColumn(\"total_payment\", F.col(\"discounted_price\") * F.col(\"quantity\"))\n",
    "    .withColumn(\"payment_method_num\", F.when(F.col(\"payment_method\") == \"credit_card\", 1).when(F.col(\"payment_method\") == \"bank_transfer\", 2).otherwise(0))  # ê¸°í ê²°ì  ìë¨ ì²ë¦¬\n",
    "    .withColumn(\"purchase_hour\", F.hour(F.to_timestamp(\"purchase_time\")))\n",
    "    .withColumn(\"hour_period\", F.when(F.col(\"purchase_hour\") < 12, \"ì¤ì \").when(F.col(\"purchase_hour\") < 18, \"ì¤í\").otherwise(\"ì ë\"))\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶ë ¥\n",
    "transformed_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fb7191d7-1725-44d6-ac60-19d44d392626",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView('dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "92474632-ec42-4506-a075-41492ef6beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------+--------+--------------+-------------------+----------------+-------------+------------------+-------------+-----------+\n",
      "|price|discount_rate|customer_grade|quantity|payment_method|      purchase_time|discounted_price|total_payment|payment_method_num|purchase_hour|hour_period|\n",
      "+-----+-------------+--------------+--------+--------------+-------------------+----------------+-------------+------------------+-------------+-----------+\n",
      "|10000|          0.1|           VIP|       2|   credit_card|2023-06-09 10:30:00|          8500.0|      17000.0|                 1|           10|       ì¤ì |\n",
      "|25000|         0.05|        NORMAL|       1| bank_transfer|2023-06-09 19:45:00|         23750.0|      23750.0|                 2|           19|       ì ë|\n",
      "+-----+-------------+--------------+--------+--------------+-------------------+----------------+-------------+------------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"select * , \\\n",
    "    case when customer_grade == 'VIP' then (price*(1-discount_rate-0.05)) else (price*(1-discount_rate)) end as discounted_price, \\\n",
    "    discounted_price*quantity as total_payment,\\\n",
    "    case when payment_method == 'credit_card' then 1 else 2 end as payment_method_num ,\\\n",
    "    EXTRACT(HOUR from TO_TIMESTAMP(purchase_time)) as purchase_hour , \\\n",
    "    case when EXTRACT(HOUR from TO_TIMESTAMP(purchase_time)) < 12 then 'ì¤ì ' when EXTRACT(HOUR from TO_TIMESTAMP(purchase_time)) < 18 then 'ì¤í' else 'ì ë' end as hour_period \\\n",
    "    from dat\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "dc51bd9c-78bd-4495-8940-ac03dfcbde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import (\n",
    "    functions as f,\n",
    "    SparkSession,\n",
    "    types as t\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"df_total\").getOrCreate()\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/product.csv\"\n",
    "df = spark.read.option(\"inferSchema\",'true').csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "33489f28-4b8f-4dc8-8020-c6015686144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bf727633-b8fa-41fc-8c67-659b904fa2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['name','id','price']\n",
    "df2 = df.toDF(*col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4c461b10-0cf6-4818-9223-7c1526b597b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+\n",
      "|                name|  id|price|\n",
      "+--------------------+----+-----+\n",
      "|      Whitney Duncan|2265|  899|\n",
      "|       Ebonie Hudson|2509|  762|\n",
      "|        Luise Warren|1995|  657|\n",
      "|        Kenton Floyd|2271|  829|\n",
      "|       Kasie Douglas|2507|  254|\n",
      "|          Elden Ward|1486|  369|\n",
      "|      Hyacinth Kelly|1355|  660|\n",
      "|   Alishia Stevenson|3173|  368|\n",
      "|      Amado Castillo|1465|  242|\n",
      "|       Daniell Mills|3043|   44|\n",
      "|          King Price|1579|  607|\n",
      "|       Luise Chapman|2149|  705|\n",
      "|        Hobert Grant|2858|  777|\n",
      "|       Michal Steele|1500|  519|\n",
      "|       Elenore Watts|2123|  670|\n",
      "|Cristobal Montgomery|1378|  630|\n",
      "|     Towanda Stevens|3122|  358|\n",
      "|     Hildred Sanders|3589|  193|\n",
      "|        Cordie Terry|3967|   49|\n",
      "|       Eugene Farmer|1966|  529|\n",
      "+--------------------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "48da59b7-4f50-445c-a7be-f54d74dc9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView('dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2a8ed97c-00b6-46b9-9e44-b30863e7617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.sql(\n",
    "    \"select name, sum(price) from dat group by name order by sum(price) desc\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c2f11f46-bd07-428a-a9b9-ff66626d4041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|             name|sum(price)|\n",
      "+-----------------+----------+\n",
      "|     Damion Wolfe|      1397|\n",
      "| Benedict Frazier|       998|\n",
      "|  Giuseppe Miller|       997|\n",
      "|    Garret Martin|       997|\n",
      "|Erminia Robertson|       997|\n",
      "|     Milan Gibson|       996|\n",
      "|     Rudy Wheeler|       994|\n",
      "|   Kathey Baldwin|       994|\n",
      "|   Williemae Bell|       992|\n",
      "|Gearldine Aguilar|       988|\n",
      "|      Jewel Parks|       987|\n",
      "|     Hyman Castro|       985|\n",
      "|    Noriko Medina|       984|\n",
      "|     Garfield Day|       982|\n",
      "|      Dacia Adams|       981|\n",
      "|     Taisha Henry|       980|\n",
      "|    Branda Valdez|       978|\n",
      "|     Fumiko Weber|       976|\n",
      "|Geraldo Alexander|       975|\n",
      "|      Walker Pope|       975|\n",
      "+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ade09bf6-139d-418c-8426-2b67144d9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import (\n",
    "    functions as f,\n",
    "    SparkSession,\n",
    "    types as t\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"df_most_interviewed\").getOrCreate()\n",
    "\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/like.csv\"\n",
    "df = spark.read.option('inferSchema','true').csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "747e4cc7-9edc-4c1c-90f4-e25a9d311fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['interviwer_id','occpation_id','rating']\n",
    "df = df.toDF(*col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9384c651-49b3-4edd-8233-bd941d346b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------+\n",
      "|interviwer_id|occpation_id|rating|\n",
      "+-------------+------------+------+\n",
      "|        11657|        1100|     8|\n",
      "|        13727|        2030|     2|\n",
      "|        59892|        3801|     1|\n",
      "|         6538|        3021|     6|\n",
      "|        95811|        2030|     9|\n",
      "|        54500|        1100|    10|\n",
      "|        69741|        2030|     3|\n",
      "|        51166|        2030|    10|\n",
      "|        70009|        9382|     5|\n",
      "|        63152|        2030|     6|\n",
      "|        70758|        1100|     2|\n",
      "|        35580|        2030|     5|\n",
      "|        63199|        1100|    10|\n",
      "|        33078|        2030|     3|\n",
      "|        97480|        9382|     2|\n",
      "|        47223|        1100|     8|\n",
      "|        80308|        3021|     8|\n",
      "|        26691|        1100|     3|\n",
      "|        17194|        3021|     3|\n",
      "|        96584|        2030|     4|\n",
      "+-------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "07be1439-5b38-4ac6-8662-0241596f8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "71f038e8-cfd6-41fe-96be-5078e8498e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"select occpation_id, count(*)  from dat group by occpation_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1c851556-c2e2-4b51-bb71-ea4b6fa8a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|occpation_id|count(1)|\n",
      "+------------+--------+\n",
      "|        1100|     217|\n",
      "|        2030|     200|\n",
      "|        3801|     203|\n",
      "|        3021|     191|\n",
      "|        9382|     189|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6340d857-0a09-41ce-ab63-1ba5d8c3ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    \"1100\": \"engineer\",\n",
    "    \"2030\": \"developer\",\n",
    "    \"3801\": \"painter\",\n",
    "    \"3021\": \"chemistry teacher\",\n",
    "    \"9382\": \"priest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "6d9e0d6c-3cab-4d18-b1da-f720a7608f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_dict = spark.sparkContext.broadcast(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1db64a35-ec24-48ce-9227-a4e1dc5ebc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupation_name(occupation_id: str) -> str:\n",
    "    return occupation_dict.value[occupation_id]\n",
    "\n",
    "occupation_lookup_udf = f.udf(get_occupation_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "8d496caf-9903-4bee-8ad3-b396ef6a9727",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[318], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df3 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moccupation_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mget_occupation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moccpation_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[316], line 2\u001b[0m, in \u001b[0;36mget_occupation_name\u001b[0;34m(occupation_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_occupation_name\u001b[39m(occupation_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moccupation_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[43moccupation_id\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Column'"
     ]
    }
   ],
   "source": [
    "df3 = df2.withColumn(\"occupation_name\", get_occupation_name(f.col('occpation_id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "39ae92d8-495a-42f4-a31c-fc3b5cdb77bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_226/3099462565.py\", line 2, in get_name\nKeyError: 1100\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[314], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:959\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    954\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    955\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/tmp/ipykernel_226/3099462565.py\", line 2, in get_name\nKeyError: 1100\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f41d8-c5bc-41ac-a3c0-007ddd9c8413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
