{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbcccbe1-2fd4-4db6-9dc0-4e934976f00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                hero|          connection|\n",
      "+--------------------+--------------------+\n",
      "|             ABCISSA|[ELSIE DEE, FURY,...|\n",
      "|             ABSALOM|[SHATTERSTAR II/G...|\n",
      "|ABSORBING MAN | MUTA|[DRAX | MUTANT X-...|\n",
      "|ABSORBING MAN/CARL C|[SOMMERS, APRIL, ...|\n",
      "|ADAMS, CONGRESSMAN H|[SPIDER-MAN/PETER...|\n",
      "| ADAMS, NICOLE NIKKI|[JUSTICE II/VANCE...|\n",
      "|    ADAMSON, REBECCA|[KABALLA, GOLEM I...|\n",
      "|               ADRIA|[DORMAMMU, ANCIEN...|\n",
      "|   ADVENT/KYLE GROBE|[JUSTICE II/VANCE...|\n",
      "|AGAMEMNON II/ANDREI |[BLACK WIDOW/NATA...|\n",
      "|      AGAMEMNON III/|[ASTER, LUCIAN, H...|\n",
      "|            AGAMOTTO|[SATANNISH, DORMA...|\n",
      "|             AGGAMON|[DR. STRANGE/STEP...|\n",
      "|              AGINAR|[SIF, REJECT/RAN-...|\n",
      "|                AGON|[MARISTA, BLACK B...|\n",
      "|     AGUIRRE, ISOBEL|[TERMINUS, HUMAN ...|\n",
      "|               AINET|[STORM/ORORO MUNR...|\n",
      "|    AKUTAGAWA, OSAMU|[HUMAN TORCH/JOHN...|\n",
      "|ALDEN, PROF. MEREDIT|[CABE, BETHANY, S...|\n",
      "|              ALIOTH|[LIBRA/GUSTAV BRA...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import (\n",
    "    functions as f,\n",
    "    SparkSession,\n",
    "    types as t\n",
    ")\n",
    "\n",
    "# Attribution 3.0 Unported (CC BY 3.0)\n",
    "# https://www.kaggle.com/datasets/csanhueza/the-marvel-universe-social-network\n",
    "\n",
    "spark = SparkSession.builder.appName(\"df_most_popular\").getOrCreate()\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/hero-network.csv\"\n",
    "# read file\n",
    "df = spark.read\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"inferSchema\", \"true\").csv(csv_file_path)\n",
    "\n",
    "\n",
    "# pyspark.sql.functions.collect_set(col): Aggregate function: returns a set of objects with duplicate elements eliminated.\n",
    "data = df.groupBy(\"hero1\").agg(f.collect_set(\"hero2\").alias(\"connection\")).withColumnRenamed(\"hero1\", \"hero\")\n",
    "data.show()\n",
    "# # pyspark.sql.functions.concat_ws(sep, *cols): Concatenates multiple input string columns together into a single string column, using the given separator.\n",
    "# data = data.withColumn(\"connection\", f.concat_ws(\",\", f.col(\"connection\")))\n",
    "# data.show()\n",
    "\n",
    "# # DataFrame.coalesce(numPartitions): Returns a new DataFrame that has exactly numPartitions partitions.\n",
    "# data.coalesce(1).write.option(\"header\", True).csv(\"output\")\n",
    "\n",
    "# # load the file\n",
    "# csv_file_path = \"file:///home/jovyan/work/output\"\n",
    "# df = spark.read\\\n",
    "#             .option(\"header\", \"true\")\\\n",
    "#             .option(\"inferSchema\", \"true\")\\\n",
    "#             .csv(csv_file_path)\n",
    "# # df.show()\n",
    "\n",
    "# # pyspark.sql.functions.size(col): Collection function: returns the length of the array or map stored in the column.\n",
    "# df = df.withColumn(\n",
    "#         \"connection_size\",\n",
    "#         f.size(\n",
    "#             f.split(f.col(\"connection\"), \",\")))\\\n",
    "#         .orderBy(f.desc(\"connection_size\"))\n",
    "# df.show()\n",
    "\n",
    "# most_popular_hero = df.select(\"hero\").first()\n",
    "# print(most_popular_hero.hero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9130122-2eb2-48cf-8b8e-01316ffff9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c3f7e-f881-45a0-bb13-595990ea05ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"inferSchema\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2abc826-db5e-4d5a-b937-281578b94846",
   "metadata": {},
   "outputs": [],
   "source": [
    "for\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/hero-network.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fbb0dab-7031-4ae2-9b7f-88e042f6c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               hero1|               hero2|\n",
      "+--------------------+--------------------+\n",
      "|       LITTLE, ABNER|      PRINCESS ZANDA|\n",
      "|       LITTLE, ABNER|BLACK PANTHER/T'CHAL|\n",
      "|BLACK PANTHER/T'CHAL|      PRINCESS ZANDA|\n",
      "|       LITTLE, ABNER|      PRINCESS ZANDA|\n",
      "|       LITTLE, ABNER|BLACK PANTHER/T'CHAL|\n",
      "|BLACK PANTHER/T'CHAL|      PRINCESS ZANDA|\n",
      "|STEELE, SIMON/WOLFGA|    FORTUNE, DOMINIC|\n",
      "|STEELE, SIMON/WOLFGA| ERWIN, CLYTEMNESTRA|\n",
      "|STEELE, SIMON/WOLFGA|IRON MAN/TONY STARK |\n",
      "|STEELE, SIMON/WOLFGA|IRON MAN IV/JAMES R.|\n",
      "|STEELE, SIMON/WOLFGA|RAVEN, SABBATH II/EL|\n",
      "|RAVEN, SABBATH II/EL|    FORTUNE, DOMINIC|\n",
      "|RAVEN, SABBATH II/EL| ERWIN, CLYTEMNESTRA|\n",
      "|RAVEN, SABBATH II/EL|IRON MAN/TONY STARK |\n",
      "|RAVEN, SABBATH II/EL|IRON MAN IV/JAMES R.|\n",
      "|IRON MAN IV/JAMES R.|    FORTUNE, DOMINIC|\n",
      "|IRON MAN IV/JAMES R.| ERWIN, CLYTEMNESTRA|\n",
      "|IRON MAN IV/JAMES R.|IRON MAN/TONY STARK |\n",
      "|IRON MAN/TONY STARK |    FORTUNE, DOMINIC|\n",
      "|IRON MAN/TONY STARK | ERWIN, CLYTEMNESTRA|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f, types as t , SparkSession\n",
    "\n",
    "\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/hero-network.csv\"\n",
    "spark = SparkSession.builder.appName(\"graph_test\").getOrCreate()\n",
    "df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(csv_file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1848d8-2e9c-4efe-afc0-f7a1939c94e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02711365-e68a-49a9-ae13-7b29f82f8898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e3ac1db-3ae4-45bf-838f-e36782edf640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|   name|          connection|\n",
      "+-------+--------------------+\n",
      "|  Alice|           [Seattle]|\n",
      "|    Bob|[San Francisco, USA]|\n",
      "|Charlie|   [KOREA, New York]|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"YourAppName\").getOrCreate()\n",
    "\n",
    "# 데이터 생성\n",
    "data = [\n",
    "    (\"Alice\", \"Seattle\"),\n",
    "    (\"Bob\", \"San Francisco\"),\n",
    "    (\"Bob\", \"USA\"),\n",
    "    (\"Charlie\", \"New York\"),\n",
    "    (\"Charlie\", \"KOREA\"),\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# \"id\" 열을 기준으로 그룹화하여 \"city\" 열의 중복 없는 값들을 집합으로 반환하여 새로운 열 \"unique_cities\" 생성\n",
    "\n",
    "data = df.groupBy(\"name\").agg(f.collect_set(\"city\").alias(\"connection\")).withColumnRenamed(\"hero1\", \"hero2\")\n",
    "\n",
    "# 결과 출력\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "250b872b-8096-4b7d-80e2-1fa51f22d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|   name|                city|\n",
      "+-------+--------------------+\n",
      "|  Alice|[Seattle, San Fra...|\n",
      "|Charlie|[San Francisco, N...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 데이터 생성\n",
    "data = [\n",
    "    (1, \"Alice\", 30, \"Seattle\"),\n",
    "    (2, \"Alice\", 25, \"San Francisco\"),\n",
    "    (2, \"Charlie\", 25, \"San Francisco\"),\n",
    "    (3, \"Charlie\", 40, \"New York\"),\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# \"id\" 열을 기준으로 분할된 윈도우에서 \"city\" 열의 중복 없는 값들을 집합으로 반환하여 새로운 열 \"unique_cities\" 생성\n",
    "data = df.groupBy(\"name\").agg(f.collect_set(\"city\").alias(\"city\"))\n",
    "# 결과 출력\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3fc65dd-2925-4962-afbb-c36249a8a077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "| name|          city|\n",
      "+-----+--------------+\n",
      "|Alice|[Seattle, USA]|\n",
      "|  Bob|    [Ban, San]|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "data = [\n",
    "    (1,\"Alice\", 30, \"Seattle\"),\n",
    "    (2,\"Bob\", 25, \"San\"),\n",
    "    (3,\"Bob\", 25, \"Ban\"),\n",
    "    (4,\"Alice\",30,\"USA\")\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\",IntegerType(),True),\n",
    "    StructField(\"name\",StringType(),True),\n",
    "    StructField(\"age\",IntegerType(),True),\n",
    "    StructField(\"city\",StringType(),True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema = schema )\n",
    "\n",
    "data = df.groupBy(\"name\").agg(f.collect_set(\"city\").alias(\"city\")).withColumnRenamed(\"a\",\"b\")\n",
    "\n",
    "data.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eaa91ae-78bb-4530-bcd6-9fb0037ce79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f, SparkSession, types as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66e4fc3-4005-4ed3-b0b9-871baf0e86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"df_most_popular\").getOrCreate()\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/hero-network.csv\"\n",
    "# read file\n",
    "df = spark.read\\\n",
    "            .option(\"header\", \"true\")\\\n",
    "            .option(\"inferSchema\", \"true\").csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db4c10a-43ac-4277-85b6-b120015058d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               hero1|               hero2|\n",
      "+--------------------+--------------------+\n",
      "|       LITTLE, ABNER|      PRINCESS ZANDA|\n",
      "|       LITTLE, ABNER|BLACK PANTHER/T'CHAL|\n",
      "|BLACK PANTHER/T'CHAL|      PRINCESS ZANDA|\n",
      "|       LITTLE, ABNER|      PRINCESS ZANDA|\n",
      "|       LITTLE, ABNER|BLACK PANTHER/T'CHAL|\n",
      "|BLACK PANTHER/T'CHAL|      PRINCESS ZANDA|\n",
      "|STEELE, SIMON/WOLFGA|    FORTUNE, DOMINIC|\n",
      "|STEELE, SIMON/WOLFGA| ERWIN, CLYTEMNESTRA|\n",
      "|STEELE, SIMON/WOLFGA|IRON MAN/TONY STARK |\n",
      "|STEELE, SIMON/WOLFGA|IRON MAN IV/JAMES R.|\n",
      "|STEELE, SIMON/WOLFGA|RAVEN, SABBATH II/EL|\n",
      "|RAVEN, SABBATH II/EL|    FORTUNE, DOMINIC|\n",
      "|RAVEN, SABBATH II/EL| ERWIN, CLYTEMNESTRA|\n",
      "|RAVEN, SABBATH II/EL|IRON MAN/TONY STARK |\n",
      "|RAVEN, SABBATH II/EL|IRON MAN IV/JAMES R.|\n",
      "|IRON MAN IV/JAMES R.|    FORTUNE, DOMINIC|\n",
      "|IRON MAN IV/JAMES R.| ERWIN, CLYTEMNESTRA|\n",
      "|IRON MAN IV/JAMES R.|IRON MAN/TONY STARK |\n",
      "|IRON MAN/TONY STARK |    FORTUNE, DOMINIC|\n",
      "|IRON MAN/TONY STARK | ERWIN, CLYTEMNESTRA|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88a9e70-4121-4b53-8fab-1fb36508defc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               hero1|          connection|\n",
      "+--------------------+--------------------+\n",
      "|             ABCISSA|[ELSIE DEE, FURY,...|\n",
      "|             ABSALOM|[SHATTERSTAR II/G...|\n",
      "|ABSORBING MAN | MUTA|[DRAX | MUTANT X-...|\n",
      "|ABSORBING MAN/CARL C|[SOMMERS, APRIL, ...|\n",
      "|ADAMS, CONGRESSMAN H|[SPIDER-MAN/PETER...|\n",
      "| ADAMS, NICOLE NIKKI|[JUSTICE II/VANCE...|\n",
      "|    ADAMSON, REBECCA|[KABALLA, GOLEM I...|\n",
      "|               ADRIA|[DORMAMMU, ANCIEN...|\n",
      "|   ADVENT/KYLE GROBE|[JUSTICE II/VANCE...|\n",
      "|AGAMEMNON II/ANDREI |[BLACK WIDOW/NATA...|\n",
      "|      AGAMEMNON III/|[ASTER, LUCIAN, H...|\n",
      "|            AGAMOTTO|[SATANNISH, DORMA...|\n",
      "|             AGGAMON|[DR. STRANGE/STEP...|\n",
      "|              AGINAR|[SIF, REJECT/RAN-...|\n",
      "|                AGON|[MARISTA, BLACK B...|\n",
      "|     AGUIRRE, ISOBEL|[TERMINUS, HUMAN ...|\n",
      "|               AINET|[STORM/ORORO MUNR...|\n",
      "|    AKUTAGAWA, OSAMU|[HUMAN TORCH/JOHN...|\n",
      "|ALDEN, PROF. MEREDIT|[CABE, BETHANY, S...|\n",
      "|              ALIOTH|[LIBRA/GUSTAV BRA...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df.groupBy(\"hero1\").agg(f.collect_set(\"hero2\").alias(\"connection\"))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84a10301-31dd-4618-99af-8787c4275ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               hero1|          connection|\n",
      "+--------------------+--------------------+\n",
      "|             ABCISSA|ELSIE DEE,FURY, C...|\n",
      "|             ABSALOM|SHATTERSTAR II/GA...|\n",
      "|ABSORBING MAN | MUTA|DRAX | MUTANT X-V...|\n",
      "|ABSORBING MAN/CARL C|SOMMERS, APRIL,HE...|\n",
      "|ADAMS, CONGRESSMAN H|SPIDER-MAN/PETER ...|\n",
      "| ADAMS, NICOLE NIKKI|JUSTICE II/VANCE ...|\n",
      "|    ADAMSON, REBECCA|KABALLA,GOLEM III...|\n",
      "|               ADRIA|DORMAMMU,ANCIENT ...|\n",
      "|   ADVENT/KYLE GROBE|JUSTICE II/VANCE ...|\n",
      "|AGAMEMNON II/ANDREI |BLACK WIDOW/NATASHA |\n",
      "|      AGAMEMNON III/|ASTER, LUCIAN,HOG...|\n",
      "|            AGAMOTTO|SATANNISH,DORMAMM...|\n",
      "|             AGGAMON|DR. STRANGE/STEPHEN |\n",
      "|              AGINAR|SIF,REJECT/RAN-SA...|\n",
      "|                AGON|MARISTA,BLACK BOL...|\n",
      "|     AGUIRRE, ISOBEL|TERMINUS,HUMAN TO...|\n",
      "|               AINET|STORM/ORORO MUNRO...|\n",
      "|    AKUTAGAWA, OSAMU|HUMAN TORCH/JOHNN...|\n",
      "|ALDEN, PROF. MEREDIT|CABE, BETHANY,STO...|\n",
      "|              ALIOTH|LIBRA/GUSTAV BRAN...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumn(\"connection\", f.concat_ws(\",\", f.col(\"connection\")))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a53b4ff-77ab-4df6-a42c-3d2c346c07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.coalesce(1).write.option(\"header\", True).csv(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c5423-fe7a-4bf1-8f4a-c8aad49b7d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
