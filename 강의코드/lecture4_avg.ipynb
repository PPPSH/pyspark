{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7d04e5-53c2-4748-90bd-1b5c5348c2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10000, 4.0), (40000, 7.0), (5000, 7.0), (4000, 2.0), (9000, 4.0), (8000, 9.0)]\n"
     ]
    }
   ],
   "source": [
    "import pyspark \n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "test_file = \"file:///home/jovyan/work/sample/house_price.csv\"\n",
    "\n",
    "def parse_line(line: str):\n",
    "    city, price, count = line.split(',')\n",
    "    return (int(price), int(count))\n",
    "\n",
    "lines = sc.textFile(test_file)\n",
    "price_count = lines.map(parse_line)\n",
    "# [(10000, 3), (10000, 5), (40000, 7), (5000, 7), (4000, 2), (9000, 4), (5000, 7), (4000, 2), (8000, 9)]\n",
    "\n",
    "sum_of_count = price_count.mapValues(lambda count: (count, 1))\\\n",
    "                .reduceByKey(lambda a, b: (int(a[0]) + int(b[0]), int(a[1]) + int(b[1]))) \n",
    "\n",
    "# ('10000', (3, 1)), ('10000', (5, 1)) ...\n",
    "# [('10000', (8, 2)), ('4000', (4, 2)), ('9000', ('4', 1)), ('8000', ('9', 1)), ('40000', ('7', 1)), ('5000', (14, 2))]\n",
    "\n",
    "avg_by_count = sum_of_count.mapValues(lambda total_count: int(total_count[0]) / total_count[1])\n",
    "results = avg_by_count.collect()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd469d3c-6453-41b0-b348-cd1d0cbdec8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10000, 4.0),\n",
       " (40000, 7.0),\n",
       " (5000, 7.0),\n",
       " (4000, 2.0),\n",
       " (9000, 4.0),\n",
       " (8000, 9.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d354e0d2-f77d-4c5b-aeaf-938bac1ba447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import pyspark \n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate();\n",
    "test_file = \"file:///home/jovyan/work/sample/house_price.csv\"\n",
    "\n",
    "txt_file = sc.textFile(test_file)\n",
    "\n",
    "def idx_parser (line : str) :\n",
    "    city, price, cnt = line.split(\",\")\n",
    "    return (int(price), int(cnt))\n",
    "\n",
    "price_cnt = txt_file.map(idx_parser)\n",
    "\n",
    "price_cnt.collect()\n",
    "\n",
    "price_cnt.mapValues(lambda a : (a,1)).collect()\n",
    "\n",
    "result = price_cnt.mapValues(lambda a : (a,1)).reduceByKey(lambda a,b : (a[0]+b[0], a[1]+b[1])).mapValues(lambda a : a[0]/a[1]).collect()\n",
    "\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c01569e6-50e5-4fb5-8a54-f8045af6e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10000, 4.0), (40000, 7.0), (5000, 7.0), (4000, 2.0), (9000, 4.0), (8000, 9.0)]\n"
     ]
    }
   ],
   "source": [
    "import pyspark \n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate();\n",
    "test_file = \"file:///home/jovyan/work/sample/house_price.csv\"\n",
    "\n",
    "def parse_line(line: str):\n",
    "    city, price, count = line.split(',')\n",
    "    return (int(price), int(count))\n",
    "\n",
    "lines = sc.textFile(test_file)\n",
    "price_count = lines.map(parse_line)\n",
    "# [(10000, 3), (10000, 5), (40000, 7), (5000, 7), (4000, 2), (9000, 4), (5000, 7), (4000, 2), (8000, 9)]\n",
    "\n",
    "sum_of_count = price_count.mapValues(lambda count: (count, 1))\\\n",
    "                .reduceByKey(lambda a, b: (int(a[0]) + int(b[0]), int(a[1]) + int(b[1]))) \n",
    "\n",
    "# ('10000', (3, 1)), ('10000', (5, 1)) ...\n",
    "# [('10000', (8, 2)), ('4000', (4, 2)), ('9000', ('4', 1)), ('8000', ('9', 1)), ('40000', ('7', 1)), ('5000', (14, 2))]\n",
    "\n",
    "avg_by_count = sum_of_count.mapValues(lambda total_count: int(total_count[0]) / total_count[1])\n",
    "results = avg_by_count.collect()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4303f4-2327-434d-9ec5-d66dd11bfa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16d7ace4-d33c-4aed-a398-7f38c282c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "test_file = \"file:///home/jovyan/work/sample/temperature.csv\"\n",
    "lines = sc.textFile(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e242bc6-ccc1-496c-9182-b5716b2ce030",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_line.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af5f083-9d73-43f2-821b-6f6991595bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_parse(line, header):\n",
    "    if line !=header:\n",
    "        col = line.split(\",\")\n",
    "        city = col[6].strip(\"\\\"\")\n",
    "        avg_tmp =col[4]\n",
    "        yield(city, avg_tmp)\n",
    "\n",
    "parse_line = lines.flatMap(lambda line : col_parse(line,header))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bba0b4c-46ca-4ff4-b364-8fa9e2fd95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_line = parse_line.filter(lambda x : \"NA\" not in x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71b9c330-1f0a-4303-b852-fbea07efc7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Auckland', '49.856'),\n",
       " ('Canoas', '50.009'),\n",
       " ('Cape Town', '49.9946'),\n",
       " ('Hamilton', '44.564'),\n",
       " ('Kherson', '10.04'),\n",
       " ('Kiev', '10.1264'),\n",
       " ('Lvov', '10.4576'),\n",
       " ('Marseille', '39.3908'),\n",
       " ('Odesa', '14.8838'),\n",
       " ('Stockholm', '13.3988'),\n",
       " ('Wroclaw', '10.436'),\n",
       " ('NA', '12.4682'),\n",
       " ('Brasília', '62.9744'),\n",
       " ('Johannesburg', '42.1772'),\n",
       " ('Paris', '25.0232'),\n",
       " ('Tokyo', '29.156'),\n",
       " ('Tottori', '34.2518'),\n",
       " ('Uppsala', '10.4432'),\n",
       " ('Warsaw', '10.4414')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_line.reduceByKey(lambda a,b : min(a,b)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a793622-9cca-4709-8abe-4474bae66b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Auckland', '49.856'),\n",
       " ('Canoas', '50.009'),\n",
       " ('Cape Town', '49.9946'),\n",
       " ('Hamilton', '44.564'),\n",
       " ('Kherson', '10.04'),\n",
       " ('Kiev', '10.1264'),\n",
       " ('Lvov', '10.4576'),\n",
       " ('Marseille', '39.3908'),\n",
       " ('Odesa', '14.8838'),\n",
       " ('Stockholm', '13.3988'),\n",
       " ('Wroclaw', '10.436'),\n",
       " ('NA', '12.4682'),\n",
       " ('Brasília', '62.9744'),\n",
       " ('Johannesburg', '42.1772'),\n",
       " ('Paris', '25.0232'),\n",
       " ('Tokyo', '29.156'),\n",
       " ('Tottori', '34.2518'),\n",
       " ('Uppsala', '10.4432'),\n",
       " ('Warsaw', '10.4414')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_line.reduceByKey(min).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4fcda-8526-470d-8ad6-379759a03bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
