{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ebc1b5-eb60-4876-ace9-dd81d70f0981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100: 217\n",
      "3801: 203\n",
      "2030: 200\n",
      "3021: 191\n",
      "9382: 189\n",
      "+-------------+-----+-----------------+\n",
      "|occupation_id|count|  occupation_name|\n",
      "+-------------+-----+-----------------+\n",
      "|         1100|  217|         engineer|\n",
      "|         3801|  203|          painter|\n",
      "|         2030|  200|        developer|\n",
      "|         3021|  191|chemistry teacher|\n",
      "|         9382|  189|           priest|\n",
      "+-------------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import (\n",
    "    functions as f,\n",
    "    SparkSession,\n",
    "    types as t\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"df_most_interviewed\").getOrCreate()\n",
    "table_schema = t.StructType([\n",
    "    t.StructField(\"interviwer_id\", t.StringType(), False),\n",
    "    t.StructField(\"occupation_id\", t.StringType(), False),\n",
    "    t.StructField(\"rating\", t.IntegerType(), False)])\n",
    "\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/like.csv\"\n",
    "df = spark.read.schema(table_schema).csv(csv_file_path)\n",
    "\n",
    "interviewer_count = df.groupBy(\"occupation_id\").count().orderBy(f.desc(\"count\"))\n",
    "\n",
    "for d in interviewer_count.select(\"occupation_id\", f.col(\"count\").alias(\"cnt\")).collect():\n",
    "    print(f\"{d.occupation_id}: {d.cnt}\")\n",
    "\n",
    "\n",
    "# But, What if we want to know what occupation_id is?  \n",
    "# 1100: engineer\n",
    "# 2030: developer\n",
    "# 3801: painter\n",
    "# 3021: chemistry teacher\n",
    "# 9382: priest\n",
    "\n",
    "meta = {\n",
    "    \"1100\": \"engineer\",\n",
    "    \"2030\": \"developer\",\n",
    "    \"3801\": \"painter\",\n",
    "    \"3021\": \"chemistry teacher\",\n",
    "    \"9382\": \"priest\"\n",
    "}\n",
    "occupation_dict = spark.sparkContext.broadcast(meta)\n",
    "\n",
    "def get_occupation_name(occupation_id: str) -> str:\n",
    "    return occupation_dict.value[occupation_id]\n",
    "\n",
    "occupation_lookup_udf = f.udf(get_occupation_name)\n",
    "\n",
    "occupation_with_name = interviewer_count.withColumn(\"occupation_name\", occupation_lookup_udf(f.col(\"occupation_id\")))\n",
    "\n",
    "occupation_with_name.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1d48c-0683-4f3e-bac5-03c476608028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d42e06d-54ad-4c36-bf7f-161414534814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|occupation_id|count(1)|\n",
      "+-------------+--------+\n",
      "|         1100|     217|\n",
      "|         3801|     203|\n",
      "|         2030|     200|\n",
      "|         3021|     191|\n",
      "|         9382|     189|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import (\n",
    "    functions as f,\n",
    "    SparkSession,\n",
    "    types as t\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"df_most_interviewed\").getOrCreate()\n",
    "table_schema = t.StructType([\n",
    "    t.StructField(\"interviwer_id\", t.StringType(), False),\n",
    "    t.StructField(\"occupation_id\", t.StringType(), False),\n",
    "    t.StructField(\"rating\", t.IntegerType(), False)])\n",
    "\n",
    "csv_file_path = \"file:///home/jovyan/work/sample/like.csv\"\n",
    "df = spark.read.schema(table_schema).csv(csv_file_path)\n",
    "\n",
    "df.createOrReplaceTempView(\"like\")\n",
    "\n",
    "spark.sql(\n",
    "    \"select occupation_id, count(*) from like group by 1 order by count(*) desc \").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f35ad8-170e-474a-87c2-8065570ca602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'engineer'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "meta = {\n",
    "    \"1100\": \"engineer\",\n",
    "    \"2030\": \"developer\",\n",
    "    \"3801\": \"painter\",\n",
    "    \"3021\": \"chemistry teacher\",\n",
    "    \"9382\": \"priest\"\n",
    "}\n",
    "\n",
    "dic = spark.sparkContext.broadcast(meta)\n",
    "\n",
    "\n",
    "dic.value[\"1100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c9891-f694-4863-ade3-340d94dfd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    \"1100\": \"engineer\",\n",
    "    \"2030\": \"developer\",\n",
    "    \"3801\": \"painter\",\n",
    "    \"3021\": \"chemistry teacher\",\n",
    "    \"9382\": \"priest\"\n",
    "}\n",
    "occupation_dict = spark.sparkContext.broadcast(meta)\n",
    "\n",
    "def get_occupation_name(occupation_id: str) -> str:\n",
    "    return occupation_dict.value[occupation_id]\n",
    "\n",
    "occupation_lookup_udf = f.udf(get_occupation_name)\n",
    "\n",
    "occupation_with_name = interviewer_count.withColumn(\"occupation_name\", occupation_lookup_udf(f.col(\"occupation_id\")))\n",
    "\n",
    "occupation_with_name.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eed3cb6-f491-4dc7-b42e-f1ed351bf81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------+\n",
      "|interviwer_id|occupation_id|rating|\n",
      "+-------------+-------------+------+\n",
      "|        11657|         1100|     8|\n",
      "|        13727|         2030|     2|\n",
      "|        59892|         3801|     1|\n",
      "|         6538|         3021|     6|\n",
      "|        95811|         2030|     9|\n",
      "|        54500|         1100|    10|\n",
      "|        69741|         2030|     3|\n",
      "|        51166|         2030|    10|\n",
      "|        70009|         9382|     5|\n",
      "|        63152|         2030|     6|\n",
      "|        70758|         1100|     2|\n",
      "|        35580|         2030|     5|\n",
      "|        63199|         1100|    10|\n",
      "|        33078|         2030|     3|\n",
      "|        97480|         9382|     2|\n",
      "|        47223|         1100|     8|\n",
      "|        80308|         3021|     8|\n",
      "|        26691|         1100|     3|\n",
      "|        17194|         3021|     3|\n",
      "|        96584|         2030|     4|\n",
      "+-------------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1337499f-d4fc-4c2b-bb3b-d05bda9faffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97810891-b6db-4e1f-93e0-6698fe04d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------+-----------------+\n",
      "|interviwer_id|occupation_id|rating|  occupation_name|\n",
      "+-------------+-------------+------+-----------------+\n",
      "|        11657|         1100|     8|         engineer|\n",
      "|        13727|         2030|     2|        developer|\n",
      "|        59892|         3801|     1|          painter|\n",
      "|         6538|         3021|     6|chemistry teacher|\n",
      "|        95811|         2030|     9|        developer|\n",
      "|        54500|         1100|    10|         engineer|\n",
      "|        69741|         2030|     3|        developer|\n",
      "|        51166|         2030|    10|        developer|\n",
      "|        70009|         9382|     5|           priest|\n",
      "|        63152|         2030|     6|        developer|\n",
      "|        70758|         1100|     2|         engineer|\n",
      "|        35580|         2030|     5|        developer|\n",
      "|        63199|         1100|    10|         engineer|\n",
      "|        33078|         2030|     3|        developer|\n",
      "|        97480|         9382|     2|           priest|\n",
      "|        47223|         1100|     8|         engineer|\n",
      "|        80308|         3021|     8|chemistry teacher|\n",
      "|        26691|         1100|     3|         engineer|\n",
      "|        17194|         3021|     3|chemistry teacher|\n",
      "|        96584|         2030|     4|        developer|\n",
      "+-------------+-------------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  pyspark.sql import functions as f\n",
    "\n",
    "meta = {\n",
    "    \"1100\": \"engineer\",\n",
    "    \"2030\": \"developer\",\n",
    "    \"3801\": \"painter\",\n",
    "    \"3021\": \"chemistry teacher\",\n",
    "    \"9382\": \"priest\"\n",
    "}\n",
    "\n",
    "\n",
    "dic = spark.sparkContext.broadcast(meta)\n",
    "\n",
    "\n",
    "\n",
    "def get_id_name ( id : str ) -> str:\n",
    "    return dic.value[id]\n",
    "\n",
    "\n",
    "udf = f.udf(get_id_name)\n",
    "\n",
    "df.withColumn(\"occupation_name\", udf(f.col(\"occupation_id\"))).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
